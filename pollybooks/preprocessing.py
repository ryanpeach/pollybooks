import os
import textwrap
from collections import defaultdict
from pathlib import Path
from typing import List

import openai

try:
    from dotenv import load_dotenv

    load_dotenv()
except:
    print("Failed to load dotenv")

MAX_TOKENS = 3000
N_CHARS_PER_TOKEN = 2


def count_tokens(text: str, n_chars_per_token: int = N_CHARS_PER_TOKEN) -> int:
    return len(text) // n_chars_per_token


def split_text_into_n_token_strings(
    text: str, max_tokens: int = MAX_TOKENS, n_chars_per_token: int = N_CHARS_PER_TOKEN
) -> List[str]:
    """
    Generated by Chat GPT:
    This function splits the input text into a list of lines using the split function
    and a newline character as the delimiter. It then iterates through the list of lines
    and adds them to the current substring until the substring has 2048 or more characters
    (assuming 4 characters per token). When the substring reaches 2048 or more characters,
    it is added to the list of substrings and the current substring is reset to be empty.
    This process is repeated until all of the lines have been processed. Finally, the
    function returns the list of substrings.
    """
    # Split the text into a list of lines
    lines = text.split("\n")

    # Initialize an empty list to store the 2048-token substrings
    substrings = []
    current_substring = ""

    # Iterate through the lines and add them to the current substring
    # until the substring has 2048 or more tokens. Then, add the substring
    # to the list of substrings and reset the current substring to be empty.
    for line in lines:
        if (
            count_tokens(
                (current_substring + "\n" + line).strip(),
                n_chars_per_token=n_chars_per_token,
            )
            >= max_tokens
        ):
            substrings.append(current_substring.strip())
            current_substring = ""
        current_substring += line + "\n"

    # Add the final substring to the list of substrings
    if current_substring.strip():
        substrings.append(current_substring.strip())

    return substrings


def convert_via_gpt(infile: Path, outpath: Path):
    """Convert a text file to a Poly compatible format"""
    with infile.open() as f:
        text = f.read()

    # Read prompts/conversion.txt
    with (Path(__file__).parent.parent / "prompts" / "conversion.txt").open() as f:
        conversion_prompt = f.read()

    conversion_prompt_tokens = count_tokens(conversion_prompt)
    print(conversion_prompt_tokens)

    # Split the text into 2,048 tokens chunks
    # Assume each token is 4 characters
    # Do not split on a sentence boundary
    chunks = split_text_into_n_token_strings(
        text, max_tokens=MAX_TOKENS - conversion_prompt_tokens
    )

    print(chunks[:5])
    # Call the openai edit api with text-ada-001
    # https://beta.openai.com/docs/api-reference/edit
    openai.api_key = os.getenv("OPENAI_API_KEY")

    all_edits = []
    for i, chunk in enumerate(chunks):
        # Write the input to a file for debugging
        with (outpath / "inchunks" / f"{i}.txt").open("w") as f:
            f.write(chunk)

        response = openai.Edit.create(
            model="text-davinci-edit-001",
            input=chunk,
            instruction=conversion_prompt,
        )

        all_edits.append(response.choices[0].text)
        break

    # Write the output to a file
    with (outpath / "output.txt").open("w") as f:
        f.write("\n".join(all_edits))


if __name__ == "__main__":
    convert_via_gpt(
        Path("./examples/preprocessing/frankenstein/source.html"),
        Path("./examples/preprocessing/frankenstein/"),
    )
